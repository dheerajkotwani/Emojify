{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files imported!\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "print(\"All files imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üî•'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fire:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üç¥'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(\":fork_and_knife:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\n",
    "    '0' : '\\u2764\\uFE0F',\n",
    "    '1' : ':baseball:',\n",
    "    '2' : ':grinning_face_with_big_eyes:',\n",
    "    '3' : ':disappointed_face:',\n",
    "    '4' : ':fork_and_knife:'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§Ô∏è\n",
      "1 ‚öæ\n",
      "2 üòÉ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "for i in emoji_dictionary:\n",
    "    print(i, emoji.emojize(emoji_dictionary[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"EmojifiedText/emojify_train_x.csv\", header=None).values\n",
    "y_train = pd.read_csv(\"EmojifiedText/Emojify_Y_train.csv\", header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"'never talk to me again' 'I am proud of your achievements'\"],\n",
       "       [\" 'It is the worst day in my life' 'Miss you so much' 'food is life'\"],\n",
       "       [\" 'I love you mum' 'Stop saying bullshit'\"],\n",
       "       [\" 'congratulations on your acceptance' 'The assignment is too long '\"],\n",
       "       [\" 'I want to go play' 'she did not answer my text '\"],\n",
       "       [\" 'Your stupidity has no limit' 'how many points did he score'\"],\n",
       "       [\" 'my algorithm performs poorly' 'I got approved' 'Stop shouting at me'\"],\n",
       "       [\" 'Sounds like a fun plan ha ha' 'no one likes him' 'the game just finished'\"],\n",
       "       [\" 'I will celebrate soon' 'So sad you are not coming'\"],\n",
       "       [\" 'She is my dearest love' 'Good job' 'It was funny lol' 'candy is life '\"],\n",
       "       [\" 'The chicago cubs won again' 'I am hungry'\"],\n",
       "       [\" 'I am so excited to see you after so long' 'you did well on you exam'\"],\n",
       "       [\" 'lets brunch some day' 'he is so cute' 'How dare you ask that'\"],\n",
       "       [\" 'do you want to join me for dinner ' 'I said yes' 'she is attractive'\"],\n",
       "       [\" 'you suck' 'she smiles a lot' 'he is laughing'\"],\n",
       "       [\" 'she takes forever to get ready ' 'French macaroon is so tasty'\"],\n",
       "       [\" 'we made it' 'I am excited' 'I adore my dogs' 'Congratulations'\"],\n",
       "       [\" 'this girl was mean' 'you two are cute'\"],\n",
       "       [\" 'my code is working but the grader gave me zero'\"],\n",
       "       [\" 'this joke is killing me haha' 'do you like pizza ' 'you got a down grade'\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_X_data(X_train):\n",
    "    data = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        data.append([x for x in X_train[i][0].split(\"\\'\") if x not in [\" \",\"\"]])\n",
    "\n",
    "    \n",
    "    X_train = flatten(data)[:-1]\n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_y_data(y_train):\n",
    "    y_train = flatten(y_train)\n",
    "    y_train = [x.split() for x in y_train]\n",
    "    y_train = np.array(flatten(y_train))\n",
    "    \n",
    "    return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_X_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = read_y_data(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_x_y_data(X,y):\n",
    "    d= []\n",
    "    for i in X:\n",
    "        d.append(i.split())\n",
    "    X = np.array(d)\n",
    "    y = np_utils.to_categorical(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['never talk to me again', 'I am proud of your achievements',\n",
       "       'It is the worst day in my life', 'Miss you so much',\n",
       "       'food is life', 'I love you mum', 'Stop saying bullshit',\n",
       "       'congratulations on your acceptance',\n",
       "       'The assignment is too long ', 'I want to go play',\n",
       "       'she did not answer my text ', 'Your stupidity has no limit',\n",
       "       'how many points did he score', 'my algorithm performs poorly',\n",
       "       'I got approved', 'Stop shouting at me',\n",
       "       'Sounds like a fun plan ha ha', 'no one likes him',\n",
       "       'the game just finished', 'I will celebrate soon'], dtype='<U52')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÉ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n",
      "she did not answer my text  üòû\n",
      "Your stupidity has no limit üòû\n",
      "how many points did he score ‚öæ\n",
      "my algorithm performs poorly üòû\n",
      "I got approved üòÉ\n",
      "Stop shouting at me üòû\n",
      "Sounds like a fun plan ha ha üòÉ\n",
      "no one likes him üòû\n",
      "the game just finished ‚öæ\n",
      "I will celebrate soon üòÉ\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(X_train[i]  , emoji.emojize(emoji_dictionary[y_train[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-aeab83adb9a3>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X = np.array(d)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = process_x_y_data(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['never', 'talk', 'to', 'me', 'again']),\n",
       "       list(['I', 'am', 'proud', 'of', 'your', 'achievements']),\n",
       "       list(['It', 'is', 'the', 'worst', 'day', 'in', 'my', 'life']),\n",
       "       list(['Miss', 'you', 'so', 'much']), list(['food', 'is', 'life']),\n",
       "       list(['I', 'love', 'you', 'mum']),\n",
       "       list(['Stop', 'saying', 'bullshit']),\n",
       "       list(['congratulations', 'on', 'your', 'acceptance']),\n",
       "       list(['The', 'assignment', 'is', 'too', 'long']),\n",
       "       list(['I', 'want', 'to', 'go', 'play']),\n",
       "       list(['she', 'did', 'not', 'answer', 'my', 'text']),\n",
       "       list(['Your', 'stupidity', 'has', 'no', 'limit']),\n",
       "       list(['how', 'many', 'points', 'did', 'he', 'score']),\n",
       "       list(['my', 'algorithm', 'performs', 'poorly']),\n",
       "       list(['I', 'got', 'approved']),\n",
       "       list(['Stop', 'shouting', 'at', 'me']),\n",
       "       list(['Sounds', 'like', 'a', 'fun', 'plan', 'ha', 'ha']),\n",
       "       list(['no', 'one', 'likes', 'him']),\n",
       "       list(['the', 'game', 'just', 'finished']),\n",
       "       list(['I', 'will', 'celebrate', 'soon'])], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5)\n",
      "(132,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f  = open(\"glove.6B.50D.txt\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values  = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float')\n",
    "    \n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.4295e-01 -4.2946e-01 -5.4277e-01 -1.0307e+00  1.2056e+00 -2.7174e-01\n",
      " -6.3561e-01 -1.5065e-02  3.7856e-01  4.6474e-02 -1.3102e-01  6.0500e-01\n",
      "  1.6391e+00  2.3940e-01  1.2128e+00  8.3178e-01  7.3893e-01  1.5200e-01\n",
      " -1.4175e-01 -8.8384e-01  2.0829e-02 -3.2545e-01  1.8035e+00  1.0045e+00\n",
      "  5.8484e-01 -6.2031e-01 -4.3296e-01  2.3562e-01  1.3027e+00 -8.1264e-01\n",
      "  2.3158e+00  1.1030e+00 -6.0608e-01  1.0101e+00 -2.2426e-01  1.8908e-02\n",
      " -1.0931e-01  3.8350e-01  7.7362e-01 -8.1927e-02 -3.4040e-01 -1.5143e-03\n",
      " -5.6640e-02  8.7359e-01  1.4805e+00  6.9421e-01 -3.0966e-01 -9.0826e-01\n",
      "  3.7277e-03  8.4550e-01]\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index['eat'])\n",
    "print(embeddings_index['eat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen = 10\n",
    "    emb_dim = 50\n",
    "    embedding_out = np.zeros((X.shape[0],maxLen,emb_dim))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "#         X[i] = X[i].split()\n",
    "        \n",
    "        for j in range(len(X[i])):\n",
    "            # go to every word in current (i) word\n",
    "            try:\n",
    "                embedding_out[i][j] = embeddings_index[X[i][j].lower()]\n",
    "            except:\n",
    "                embedding_out[i][j] = np.zeros((50,))\n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_X_train = embedding_output(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 10, 50)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(10,50),return_sequences=True)) # max 10 words per sentence, each of 50 dim\n",
    "model.add(Dropout(0.5))\n",
    "model.add((LSTM(64,return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics =[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 13s 3s/step - loss: 1.5863 - accuracy: 0.2473 - val_loss: 1.6230 - val_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.5446 - accuracy: 0.3536 - val_loss: 1.6203 - val_accuracy: 0.2222\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.5087 - accuracy: 0.4073 - val_loss: 1.6300 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.5093 - accuracy: 0.3148 - val_loss: 1.6480 - val_accuracy: 0.2222\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.4995 - accuracy: 0.3148 - val_loss: 1.6615 - val_accuracy: 0.2963\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 1.4594 - accuracy: 0.3506 - val_loss: 1.6736 - val_accuracy: 0.2593\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 1.4267 - accuracy: 0.3518 - val_loss: 1.6785 - val_accuracy: 0.2593\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.4580 - accuracy: 0.3969 - val_loss: 1.6699 - val_accuracy: 0.2222\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 1.4121 - accuracy: 0.3969 - val_loss: 1.6466 - val_accuracy: 0.1852\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.3678 - accuracy: 0.4442 - val_loss: 1.6037 - val_accuracy: 0.2222\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 1.3515 - accuracy: 0.4442 - val_loss: 1.5464 - val_accuracy: 0.2963\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.2886 - accuracy: 0.5061 - val_loss: 1.4742 - val_accuracy: 0.2593\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2766 - accuracy: 0.4749 - val_loss: 1.4020 - val_accuracy: 0.2963\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 1.2445 - accuracy: 0.4991 - val_loss: 1.3576 - val_accuracy: 0.3704\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.2147 - accuracy: 0.5483 - val_loss: 1.3243 - val_accuracy: 0.4444\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.1514 - accuracy: 0.5748 - val_loss: 1.2977 - val_accuracy: 0.4444\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.1042 - accuracy: 0.5188 - val_loss: 1.2973 - val_accuracy: 0.5185\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.0380 - accuracy: 0.6210 - val_loss: 1.2973 - val_accuracy: 0.4815\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 1.0477 - accuracy: 0.5517 - val_loss: 1.2582 - val_accuracy: 0.4815\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.0038 - accuracy: 0.5644 - val_loss: 1.2531 - val_accuracy: 0.4815\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.9612 - accuracy: 0.6401 - val_loss: 1.2418 - val_accuracy: 0.5556\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.9638 - accuracy: 0.6222 - val_loss: 1.2232 - val_accuracy: 0.5556\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.9609 - accuracy: 0.6297 - val_loss: 1.2363 - val_accuracy: 0.5185\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 0.8921 - accuracy: 0.7169 - val_loss: 1.3527 - val_accuracy: 0.5185\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.9599 - accuracy: 0.5927 - val_loss: 1.3102 - val_accuracy: 0.5185\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8290 - accuracy: 0.6528 - val_loss: 1.1661 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.7925 - accuracy: 0.7128 - val_loss: 1.1930 - val_accuracy: 0.5556\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6761 - accuracy: 0.7631 - val_loss: 1.3097 - val_accuracy: 0.5185\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7774 - accuracy: 0.7233 - val_loss: 1.3767 - val_accuracy: 0.4815\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.6871 - accuracy: 0.7493 - val_loss: 1.2453 - val_accuracy: 0.4815\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6799 - accuracy: 0.7684 - val_loss: 1.1629 - val_accuracy: 0.5185\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5477 - accuracy: 0.8452 - val_loss: 1.2020 - val_accuracy: 0.5185\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.5900 - accuracy: 0.7631 - val_loss: 1.3469 - val_accuracy: 0.5185\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.5145 - accuracy: 0.8377 - val_loss: 1.3136 - val_accuracy: 0.5185\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.5165 - accuracy: 0.7758 - val_loss: 1.2627 - val_accuracy: 0.5926\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.5424 - accuracy: 0.7949 - val_loss: 1.2463 - val_accuracy: 0.5556\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4295 - accuracy: 0.8660 - val_loss: 1.2598 - val_accuracy: 0.5926\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.4525 - accuracy: 0.8579 - val_loss: 1.2691 - val_accuracy: 0.5556\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.5094 - accuracy: 0.8094 - val_loss: 1.1475 - val_accuracy: 0.5926\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.4089 - accuracy: 0.8683 - val_loss: 1.1862 - val_accuracy: 0.5556\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.3946 - accuracy: 0.8810 - val_loss: 1.1470 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.4046 - accuracy: 0.8550 - val_loss: 1.2364 - val_accuracy: 0.6296\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.3078 - accuracy: 0.8989 - val_loss: 1.4281 - val_accuracy: 0.5556\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.3135 - accuracy: 0.8799 - val_loss: 1.5321 - val_accuracy: 0.5556\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.2974 - accuracy: 0.9209 - val_loss: 1.5436 - val_accuracy: 0.6296\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.2814 - accuracy: 0.9209 - val_loss: 1.5501 - val_accuracy: 0.5926\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3618 - accuracy: 0.8810 - val_loss: 1.3393 - val_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.2875 - accuracy: 0.8989 - val_loss: 1.1852 - val_accuracy: 0.7037\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.2451 - accuracy: 0.9399 - val_loss: 1.2022 - val_accuracy: 0.6296\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2889 - accuracy: 0.9105 - val_loss: 1.3868 - val_accuracy: 0.5926\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.3304 - accuracy: 0.9000 - val_loss: 1.5282 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "modelcheckpoint = ModelCheckpoint(\"best_model.h5\",save_best_only=True)\n",
    "earlystop = EarlyStopping(patience=10 , monitor='val_loss',restore_best_weights=True)\n",
    "\n",
    "hist = model.fit(embedded_X_train, y_train, epochs=100, batch_size=64, callbacks=[modelcheckpoint,earlystop], shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-aeab83adb9a3>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X = np.array(d)\n",
      "<ipython-input-50-892961c843ed>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X_test = np.array(a)\n"
     ]
    }
   ],
   "source": [
    "X_test = pd.read_csv(\"EmojifiedText/emojiy_test_x.csv\", header=None).values\n",
    "y_test = pd.read_csv(\"EmojifiedText/emojiy_y_test.csv\", header=None).values\n",
    "\n",
    "X_test = read_X_data(X_test)\n",
    "y_test = read_y_data(y_test)\n",
    "\n",
    "X_test, y_test = process_x_y_data(X_test,y_test)\n",
    "\n",
    "for i in X_test:\n",
    "    i[-1] = i[-1].replace(\"\\\\t\",\"\", True)\n",
    "    \n",
    "    \n",
    "a = list(X_test)\n",
    "a.append(['I', 'did', 'not', 'have', 'breakfast'])\n",
    "X_test = np.array(a)    \n",
    "\n",
    "embedded_X_test = embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 0 2 2 1 2 4 2 1 2 3 3 1 3 2 0 3 4 3 0 2 2 3 1 3 0 1 2 0 1 0 2 0 1 2\n",
      " 4 0 2 1 0 0 1 2 0 3 2 3 3 1 3 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(embedded_X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8642 - accuracy: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8642193675041199, 0.6785714030265808]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embedded_X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "he did not answer\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "he got a very nice raise\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "she got me a nice present\n",
      "actual label - üòÉ\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "ha ha ha it was so funny\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "he is a good friend\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "I am upset\n",
      "actual label - üòû\n",
      "predicted label - ‚öæ\n",
      "\n",
      "We had such a lovely dinner tonight\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "where is the food\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "Stop making this joke ha ha ha\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n",
      "where is the ball\n",
      "actual label - ‚öæ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "work is hard\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "This girl is messing with me\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "are you serious\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "Let us go play baseball\n",
      "actual label - ‚öæ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "This stupid grader is not working \n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "work is horrible\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "Congratulation for having a baby\n",
      "actual label - üòÉ\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "stop pissing me off\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "any suggestions for dinner\n",
      "actual label - üç¥\n",
      "predicted label - üç¥\n",
      "\n",
      "I love taking breaks\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - üòû\n",
      "\n",
      "you brighten my day\n",
      "actual label - üòÉ\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "I boiled rice\n",
      "actual label - üç¥\n",
      "predicted label - üòÉ\n",
      "\n",
      "she is a bully\n",
      "actual label - üòû\n",
      "predicted label - üòÉ\n",
      "\n",
      "Why are you feeling bad\n",
      "actual label - üòû\n",
      "predicted label - üòû\n",
      "\n",
      "I am upset\n",
      "actual label - üòû\n",
      "predicted label - ‚öæ\n",
      "\n",
      "give me the ball\n",
      "actual label - ‚öæ\n",
      "predicted label - üòû\n",
      "\n",
      "My grandmother is the love of my life\n",
      "actual label - ‚ù§Ô∏è\n",
      "predicted label - ‚ù§Ô∏è\n",
      "\n",
      "enjoy your game\n",
      "actual label - ‚öæ\n",
      "predicted label - ‚öæ\n",
      "\n",
      "valentine day is near\n",
      "actual label - üòÉ\n",
      "predicted label - üòÉ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\" \".join(X_test[i]))\n",
    "    print(\"actual label -\", emoji.emojize(emoji_dictionary[str(y_test[i].argmax())]))\n",
    "    print(\"predicted label -\", emoji.emojize(emoji_dictionary[str(pred[i])]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
